
<span class='anchor' id='about-me'></span>
---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class="anchor" id="about-me"></span>

## ğŸ‘‹ About Me

I am currently a research assistant at the [School of Data Science (SDS), The Chinese University of Hong Kong, Shenzhen](https://sds.cuhk.edu.cn/), where I work under the supervision of [Prof. Lihai Zhou](https://scholar.google.com/citations?hl=zh-CN&user=z8_x7C8AAAAJ) and [Prof. Benyou Wang](https://wabyking.github.io/old.html). My research focuses on **[LLMs Interpretability & Trustworthy AI](https://www.anthropic.com/research#interpretability)**, aiming to better understand large language models and to design more advanced and safer AI systems.

Previously, I earned my Bachelorâ€™s degree from the [University of Electronic Science and Technology of China (UESTC)](https://www.uestc.edu.cn/) and obtained my Masterâ€™s degree in Artificial Intelligence from the [Faculty of Science, The University of Hong Kong (HKU)](https://www.scifac.hku.hk/). I am also an incoming Ph.D. student in AI at the [Department of Data Science, HKU](https://datascience.hku.hk/), advised by [Prof. Difan Zou](https://difanzou.github.io/).

My current research interest lies in understanding the inner mechanisms of large models to plan for a future of safe AI. In particular, I am actively exploring **Circuit Analysis** (https://arxiv.org/abs/2502.11812) and **Sparse Autoencoders (SAEs)** (https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html), with the long-term goal of (1) understanding how LLMs work internally, (2) improving their performance, and (3) building models that are safer and more controllable.

If you would like to get in touchâ€”or share a passion for LLM interpretability and safetyâ€”feel free to reach out via email: **sunny615@connect.hku.hk**.

---

<span class="anchor" id="news"></span>

## ğŸ—ï¸ News

- ğŸ“ *[2025.05]* Paper **"Understanding Fine-tuning via Circuit Changes in LLMs"** accepted at **ICLR 2025 Workshop**
- ğŸ’¡ *[2025.03]* Selected for AI-Healthcare integration project at HKU
- ğŸ“ *[2023.09]* Started Master's at **The University of Hong Kong**

---

<span class="anchor" id="publications"></span>

## ğŸ“„ Publications

- **Wang, Xu**, et al. *Understanding Circuit Changes in Fine-tuned LLMs*  
  _ICLR 2025 Workshop (accepted)_

- **Wang, Xu**, et al. *Generative AI for Healthcare Applications: A Case Study*  
  _SEDSI 2025 (accepted)_

---

<span class="anchor" id="experience"></span>

## ğŸ’¼ Experience

### ğŸ”¬ Research

- **Circuit Changes in Fine-tuned LLMs** â€“ *ICLR 2025 Workshop*  
  Used EAP-IG to extract circuits in GPT2-xl, Pythia, and Llama3; analyzed structure-level changes under fine-tuning.

- **AI Doctor Assistant using Llama 3** â€“ *SEDSI 2025*  
  Fine-tuned Llama 3.1-8B on medical QA and KG data; implemented RAG using LangChain to enhance relevance.

- **Multi-choice Reasoning with Phi2**  
  Optimized in-context learning, embeddings, and hyperparameters for improved multi-choice Q&A performance.

### ğŸ¢ Internships (iFLYTEK Group, multiple roles)

- ğŸ—£ï¸ Speech recognition and multi-modal data processing (Hefei)
- ğŸ§  Sentiment analysis via NLP/ML (Hefei)
- ğŸ”Š Robustness optimization in noisy audio (Hangzhou)

---

<span class="anchor" id="future-plan"></span>

## ğŸ§­ Future Plan

- ğŸ” Continue exploring **LLM interpretability** and **mechanistic transparency**  
- ğŸ§  Expand work into **model editing**, **knowledge attribution**, and **long-context memory**
- ğŸ›¡ï¸ Contribute to **safe alignment** and **auditability** of foundation models
- ğŸŒ Collaborate on **open-source AI safety toolkits**



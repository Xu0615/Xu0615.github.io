---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>
---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class="anchor" id="about-me"></span>

## ğŸ‘‹ About Me

Hi! I'm **Xu Wang**, currently pursuing an M.Sc. in Artificial Intelligence at **The University of Hong Kong (HKU)** ğŸ§ , expected to graduate in 2025. I hold a B.Eng. in Information Systems from **University of Electronic Science and Technology of China (UESTC)**, where I graduated with a GPA of **3.93/4.0** ğŸ“š.

My research focuses on **Large Language Models (LLMs)**, with particular interest in:
- ğŸ§© *Interpretability & circuit tracing*
- ğŸ§ª *Fine-tuning mechanisms (LoRA, AdaLoRA, IA3)*
- ğŸ©º *Safe applications in healthcare*
- ğŸ›¡ï¸ *Responsible AI and AI alignment*

Currently, I am a research assistant at HKU and CUHK (Shenzhen), working on projects related to **LLM interpretability and AI safety**.

---

<span class="anchor" id="news"></span>

## ğŸ—ï¸ News

- ğŸ“ *[2025.05]* Paper **"Understanding Fine-tuning via Circuit Changes in LLMs"** accepted at **ICLR 2025 Workshop**
- ğŸ’¡ *[2025.03]* Selected for AI-Healthcare integration project at HKU
- ğŸ“ *[2023.09]* Started Master's at **The University of Hong Kong**

---

<span class="anchor" id="publications"></span>

## ğŸ“„ Publications

- **Wang, Xu**, et al. *Understanding Circuit Changes in Fine-tuned LLMs*  
  _ICLR 2025 Workshop (accepted)_

- **Wang, Xu**, et al. *Generative AI for Healthcare Applications: A Case Study*  
  _SEDSI 2025 (accepted)_

---

<span class="anchor" id="experience"></span>

## ğŸ’¼ Experience

### ğŸ”¬ Research

- **Circuit Changes in Fine-tuned LLMs** â€“ *ICLR 2025 Workshop*  
  Used EAP-IG to extract circuits in GPT2-xl, Pythia, and Llama3; analyzed structure-level changes under fine-tuning.

- **AI Doctor Assistant using Llama 3** â€“ *SEDSI 2025*  
  Fine-tuned Llama 3.1-8B on medical QA and KG data; implemented RAG using LangChain to enhance relevance.

- **Multi-choice Reasoning with Phi2**  
  Optimized in-context learning, embeddings, and hyperparameters for improved multi-choice Q&A performance.

### ğŸ¢ Internships (iFLYTEK Group, multiple roles)

- ğŸ—£ï¸ Speech recognition and multi-modal data processing (Hefei)
- ğŸ§  Sentiment analysis via NLP/ML (Hefei)
- ğŸ”Š Robustness optimization in noisy audio (Hangzhou)

---

<span class="anchor" id="future-plan"></span>

## ğŸ§­ Future Plan

- ğŸ” Continue exploring **LLM interpretability** and **mechanistic transparency**  
- ğŸ§  Expand work into **model editing**, **knowledge attribution**, and **long-context memory**
- ğŸ›¡ï¸ Contribute to **safe alignment** and **auditability** of foundation models
- ğŸŒ Collaborate on **open-source AI safety toolkits**




<span class='anchor' id='about-me'></span>
---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class="anchor" id="about-me"></span>

## 👋 About Me

If you would like to get in touch—or share a passion for LLM interpretability and safety—feel free to reach out via email: **sunny615@connect.hku.hk**.

---

<span class="anchor" id="news"></span>

## 🗞️ News

- 📝 *[2025.05]* Paper **"Understanding Fine-tuning via Circuit Changes in LLMs"** accepted at **ICLR 2025 Workshop**
- 💡 *[2025.03]* Selected for AI-Healthcare integration project at HKU
- 🎓 *[2023.09]* Started Master's at **The University of Hong Kong**

---

<span class="anchor" id="publications"></span>

## 📄 Publications

- **Wang, Xu**, et al. *Understanding Circuit Changes in Fine-tuned LLMs*  
  _ICLR 2025 Workshop (accepted)_

- **Wang, Xu**, et al. *Generative AI for Healthcare Applications: A Case Study*  
  _SEDSI 2025 (accepted)_

---

<span class="anchor" id="experience"></span>

## 💼 Experience

### 🔬 Research

- **Circuit Changes in Fine-tuned LLMs** – *ICLR 2025 Workshop*  
  Used EAP-IG to extract circuits in GPT2-xl, Pythia, and Llama3; analyzed structure-level changes under fine-tuning.

- **AI Doctor Assistant using Llama 3** – *SEDSI 2025*  
  Fine-tuned Llama 3.1-8B on medical QA and KG data; implemented RAG using LangChain to enhance relevance.

- **Multi-choice Reasoning with Phi2**  
  Optimized in-context learning, embeddings, and hyperparameters for improved multi-choice Q&A performance.

### 🏢 Internships (iFLYTEK Group, multiple roles)

- 🗣️ Speech recognition and multi-modal data processing (Hefei)
- 🧠 Sentiment analysis via NLP/ML (Hefei)
- 🔊 Robustness optimization in noisy audio (Hangzhou)

---

<span class="anchor" id="future-plan"></span>

## 🧭 Future Plan

- 🔍 Continue exploring **LLM interpretability** and **mechanistic transparency**  
- 🧠 Expand work into **model editing**, **knowledge attribution**, and **long-context memory**
- 🛡️ Contribute to **safe alignment** and **auditability** of foundation models
- 🌐 Collaborate on **open-source AI safety toolkits**


